%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%12pt: grandezza carattere
                                        %a4paper: formato a4
                                        %openright: apre i capitoli a destra
                                        %twoside: serve per fare un
                                        %   documento fronteretro
                                        %report: stile tesi (oppure book)
\documentclass[12pt,a4paper,openright,oneside]{report}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per scrivere in italiano
\usepackage[italian]{babel}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per accettare i caratteri
                                        %   digitati da tastiera come � �
                                        %   si pu� usare anche
                                        %   \usepackage[T1]{fontenc}
                                        %   per� con questa libreria
                                        %   il tempo di compilazione
                                        %   aumenta
\usepackage[latin1]{inputenc}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per impostare il documento
\usepackage{fancyhdr}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per avere l'indentazione
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   all'inizio dei capitoli, ...
\usepackage{indentfirst}
%
%%%%%%%%%libreria per mostrare le etichette
%\usepackage{showkeys}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per inserire grafici
\usepackage{graphicx}
\graphicspath{{../images/}}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per utilizzare font
                                        %   particolari ad esempio
                                        %   \textsc{}
\usepackage{newlfont}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%librerie matematiche
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{latexsym}
\usepackage{amsthm}
%

\usepackage{tabto}
\usepackage[backend=biber]{biblatex}

\usepackage{listings}% http://ctan.org/pkg/listings
\lstset{
  basicstyle=\ttfamily,
  mathescape
}

\usepackage{array}
\usepackage{xcolor}

\addbibresource{tesi.bib}
\oddsidemargin=30pt \evensidemargin=20pt%impostano i margini
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%comandi per l'impostazione
                                        %   della pagina, vedi il manuale
                                        %   della libreria fancyhdr
                                        %   per ulteriori delucidazioni
\pagestyle{fancy}\addtolength{\headwidth}{20pt}
\renewcommand{\chaptermark}[1]{\markboth{\thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection \ #1}{}}
\rhead[\fancyplain{}{\bfseries\leftmark}]{\fancyplain{}{\bfseries\thepage}}
\cfoot{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\linespread{1.3}                        %comando per impostare l'interlinea
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%definisce nuovi comandi
%
\begin{document}
\begin{titlepage}                       %crea un ambiente libero da vincoli
                                        %   di margini e grandezza caratteri:
                                        %   si pu\`o modificare quello che si
                                        %   vuole, tanto fuori da questo
                                        %   ambiente tutto viene ristabilito
%
\thispagestyle{empty}                   %elimina il numero della pagina
\topmargin=6.5cm                        %imposta il margina superiore a 6.5cm
\raggedleft                             %incolonna la scrittura a destra
\large                                  %aumenta la grandezza del carattere
                                        %   a 14pt
\em                                     %emfatizza (corsivo) il carattere
Questa \`e la \textsc{Dedica}:\\
ognuno pu\`o scrivere quello che vuole, \\
anche nulla \ldots                      %\ldots lascia tre puntini
\newpage                                %va in una pagina nuova
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage{\pagestyle{empty}\cleardoublepage}%non numera l'ultima pagina sinistra
\end{titlepage}
\pagenumbering{roman}                   %serve per mettere i numeri romani
\chapter*{Introduzione}                 %crea l'introduzione (un capitolo
                                        %   non numerato)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%imposta l'intestazione di pagina
\rhead[\fancyplain{}{\bfseries
INTRODUZIONE}]{\fancyplain{}{\bfseries\thepage}}
\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries
INTRODUZIONE}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%aggiunge la voce Introduzione
                                        %   nell'indice
\addcontentsline{toc}{chapter}{Introduzione}
Questa \`e l'introduzione.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%non numera l'ultima pagina sinistra
\clearpage{\pagestyle{empty}\cleardoublepage}
\tableofcontents                        %crea l'indice
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%imposta l'intestazione di pagina
\rhead[\fancyplain{}{\bfseries\leftmark}]{\fancyplain{}{\bfseries\thepage}}
\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries
INDICE}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%non numera l'ultima pagina sinistra
\clearpage{\pagestyle{empty}\cleardoublepage}
\listoffigures                          %crea l'elenco delle figure
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%non numera l'ultima pagina sinistra
\clearpage{\pagestyle{empty}\cleardoublepage}
\listoftables                           %crea l'elenco delle tabelle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%non numera l'ultima pagina sinistra
\clearpage{\pagestyle{empty}\cleardoublepage}
\chapter{Rumore e Denoising}                %crea il capitolo
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%imposta l'intestazione di pagina
\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries\rightmark}}
\pagenumbering{arabic}                  %mette i numeri arabi
\section{Imaging}                 %crea la sezione
Con il termine \textbf{medical imaging} ci si riferisce alla generica tecnica o processo attraveso il quale \`{e} possibile osservare un' area di un organismo non visibile dall'esterno; per analisi cliniche o una rappresentazione visiva delle funzioni di organi e tessuti.\\
Una \textbf{radiografia} \`{e} una tecnica di imaging che produce un radiogramma. Tale tecnica si basa sull' utilizzo di un fascio di \textbf{fotoni}, come raggi X o raggi Gamma, generati da una sorgente e catturati da un \textbf{recettore}. \\ I raggi durante il passaggio per il corpo interposto tra la sorgente e il recettore vengono assorbiti o attenutati in maniera differente l'uno dall'altro, creando un insieme di raggi di diversa intensit\`{a}.\\ Il recettore trasforma questo insieme di raggi di diversa concentrazione in un immagine "in negativo" del corpo, essendo catturati dal recettore solo i fotoni che non vengono assorbiti dall' oggetto.\\
L'assorbimento dovuto alle diverse composizioni elementali del corpo gioca un ruolo fondamentale nell' imaging medico. Il processo di assorbimento \`{e} proporzionale al \textbf{numero atomico} della materia attraversata e questo permette di distinguere la materia grigia dalla materia bianca nell'immagine generata. Per esempio tra il sangue e il muscolo non \`{e} osservabile un contrasto elevato, essendo la densit\`{a} degli elementi che li compongono molto simile. Per generare un contrasto tra i due \`{e} necessario iniettare un liquido di contrasto composto da elementi con un alto numero atomico durante l'esposizione ai raggi.\\
I recettori localizzati in maniera opposta alla sorgente dei raggi, ricevono i fasci di fotoni e generano un segnale elettrico. Questo segnale elettrico deve essere convertito in un segnale digitale da un convertitore analogico/digitale e successivamente in un immagine. \cite{diwakar_review_2018}.


\section{Rumore}
Ci sono molti elementi che possono influenzare la qualit\`{a} dell'immagine costruita \cite{diwakar_review_2018, manson_image_nodate}, i fattori principali sono :
  \begin{itemize}
    \item Blurring: l' immagine potrebbe risultare sfocata per diverse ragioni, i motivi principali sono:
      \begin{enumerate}
        \item Uso improprio della strumentazione.
        \item Movimento dell paziente dovuto al respiro o al battito del cuore.
        \item Fluttuazioni dei valori dei pixel dell' immagine in una regione di materiale uniforme.
        \item Gli algoritmi usati per filtrare i raggi sfocano l'immagine.
      \end{enumerate}
      \item Field of View (FOV): La dimensione della regione anatomica inclusa nella scansione viene detta field of view. Se la dimensione della regione \`{e} troppo grande o troppo piccola, la qualit\`{a} dell' immagine potrebbe risultare degradata.
      \item Artefatti: Gli artefatti sono distorsioni o errori nell' immagine digitale che non dipendono dall' oggetto scansionato. Gli artefatti pi\`{u} comuni sono:
      \begin{enumerate}
        \item Beam Hardening: Il beam hardening avviene quando l'energia media di un raggio passante per il paziente aumenta. Per evitare che ci\`{o} avvenga alcune soluzioni possono essere messe in pratica, aumentare il kvp(peak kilovoltage), decrementare la grandezza delle slice(in caso di tomografia computerizzata), pre-filtrare i raggi, evitare regioni ad alto assorbimento, soluzioni algorimiche.
        \item Artefatti metallici: Materiali metallici possono causare soprattutto nelle CT i cosiddetti streaking artifacts (fasci di luce), dovuti dal blocco delle informazioni di proiezione. Per ridurre questo fenomeno \`{e} necessario rimuovere il materiale metallico se possibile.
        \item Movimento del paziente: Il movimenti volontari o involontari del paziente possono produrre streaking artifacts. Si pu\`{o} ridurre il tempo di scansione e migliorare il posizionamento del paziente.
        \item Software e Hardware: Artefatti derivanti da implementazioni o configurazioni scorrette di algoritmi di costruzione dell'immagine digitale o degradazione dei componenti elettronici e meccanici.
      \end{enumerate}
      \item Rumore Visivo: Il rumore visivo \`{e} una variazione casuale della luminosit\`{a} dei singoli pixel dell' immagine. Questo tipo di rumore deriva di solito da errori nell' acquisizione, trasmissione del segnale ed errori computazionali matematici. Questo tipo di rumore ha una maggiore influenza su soggetti a basso contrasto.
  \end{itemize}
  La dose di radiazioni a cui \`{e} sottoposto il paziente \`{e} uno dei fattori pi\`{u} importanti nella generazione di rumore. Per la sicurezza del paziente \`{e} necessario minimizzare il tempo di esposizione alle radiazioni, ma la conseguenza principale nel ridurre la dose di radiazioni \`{e} un aumento del rumore dell'immagine facendo diminuire la qualit\`{a} della diagnosi.\\
  Ci sono due approcci principali per cercare di ridurre il rumore visivo senza sacrificare la qualit\`{a} dell'immagine:
  \begin{enumerate}
    \item Facendo uno studio ed una ottimizzazione della dose di radiazioni le immagini a bassa dose di radiazioni possono essere migliorate.
    \item La qualit\`{a} dell' immagine pu\`{o} essere migliorata sviluppando algoritmi per la rimozione del rumore nelle immagini. Questi algoritmi possono essere successivamente utilizzati per ridurre la dose di radiazioni. Il processo di rimozione di rumore da immagini \`{e} conosciuto con il termine di \textbf{image denoising}.
  \end{enumerate}

  Le radiografie sono caratterizzate da una sensibilit\`{a} ai contrasti che permette di distinguere tra i diversi tessuti molli del corpo umano. Questa caratteristica \`{e} particolarmente influenzata dal rumore, che nuoce alla visualizzazione delle strutture a basso contrasto.\\
  Prima di considerare tecniche di image denoising \'{e} necessario comprendere quali sono le sorgenti principali di rumore visivo:

  \textbf{Rumore randomico e statistico:} Pu\`{o} essere generato dalla ricezione di un numero finito di quanti (pacchetti di energia) di raggi da parte del recettore. Durante il processo non c'\`{e} nessuna forza che distribuisce i fotoni in maniera uniforme sulla superfice, un area del recettore potrebbe percepire pi\`{u} fotoni di un altra. La causa principale di questo rumore \`{e} la cosiddetta radiazione secondaria \cite{manson_image_nodate}, prodotta dall'interazione dei fotoni emessi dal generatore con il corpo in scansione, disperdendo ulteriormente in maniera casuale le particelle. Il risultato del rumore viene percepito come una fluttuazione nella densit\`{a} dell' immagine, che varia in maniera randomica \cite{diwakar_review_2018}. Questo tipo di rumore \`{e} anche chiamato \textbf{rumore quantico}.

  \textbf{Rumore Elettrico:} Il processo di un circuito elettrico che riceve segnali analogici pu\`{o} generare un disturbo del segnale. La sorgente pi\`{u} comune di rumore \`{e} il rumore termico intrinseco di ogni elemento dissipativo (es. resistori) che si trovi ad una temperatura diversa dallo zero assoluto \cite{boyat_review_2015}.

  \textbf{Errori di arrotondamento:} I segnali analogici sono convertiti in segnali digitali usando algoritmi di quantizzazione del segnale. Per ricostruire l'immagine il segnale ora discreto viene elaborato da un calcolatore. La rappresentazione in memoria del segnale deve essere necessariamente finita, essendo limitata dal numero di bit usati dal sistema numerico implementato dal computer per il calcolo. La computazione matematica non \`{e} dunque possibile senza errori di arrotondamento.

  Generalmente il rumore nella ricostruzione di immagini mediche viene introdotto per due motivi. Il primo \'{e} un rumore variabile dovuto al rumore elettrico e da errori di arrotondamento e pu\`{o} essere modellato con un semplice rumore additivo. Il secondo \`{e} il rumore dovuto dalle fluttuazioni di fotoni percepiti nelle diverse zone del recettore, pi\`{u} complesso da modellizzare.\\
  Il rumore pu\`{o} essere calcolato statisticamente utilizzando la deviazione standard dell'intensit\`{a} dei pixel in una regione fisica unifome dell' immagine. L'analisi statistica dei valori dei pixel produce una distribuzione con forma a campana. La variazione standard, cio\`{e} la misura della variazione dei pixel nella zona di interesse, rappresenta il livello di rumore nell'immagine. Un valore alto della deviazione standard implica un alto livello di rumore. Questa distribuzione statistica mostra mostra che il valore medio del rumore \`{e} uguale alla varianza del rumore e pu\`{o} essere analizzato che il rapporto segnale-rumore \`{e} proporzionale alla radice quadrata della dose di raggi emessi. Dunque la quantit'\`{a} relativa di rumore quantico percepita dai recettori diminuisce all'aumentare della dose di raggi emessi. \\
  Il problema di identficare la distribuzione esatta del rumore deriva dal fatto che tutti i passi intermedi nella generazione dell'immagine introducono una correlazione statistica con i valori contenenti rumore catturati dal recettore. A causa di queste dipendenze la distribuzione esatta del rumore nell' immagine finale risulta sconosciuta.\\
  Sperimentalmente si \`{e} potuto osservare come il rumore quantico sia modellizzabile con una distribuzione di \textbf{Poisson} mentre il rumore termico con una distribuzione di \textbf{Gauss} \cite{manson_image_nodate, boyat_review_2015, diwakar_review_2018}.

\section{Denoising}
  \subsection{Approccio Classico}

    Con image denoising si intente il problema di rimuovere rumori e distorsioni da una immagine. Generalmente si considera l'immagine rumorosa come una somma tra l'immagine originale e una componente di rumore, questo comporta che l'obbiettivo delle tecniche di denoising sia quello di ridurre la componente rumorosa cercando di mantenere nell'immagine pulita le caratteristiche dell' immagine originale.\\
    Quando si tratta di denoising applicato a imaging medico l'obbiettivo del denoising \`{e} quello di ridurre il rumore mantendendo i dettagli clinici in modo tale da mantenere l'immagine utile per una corretta diagnosi.\\ Nel tempo sono stati sviluppati filtri di lisciamento (smoothing) e di sharpening. I primi in caso di alti livelli di rumore tendono a sfocare l'immagine e a non preservare i bordi dell'oggetto, mentre i filtri di sharpening non eccellono nel mantenere piccoli dettagli dell' immagine \cite{fan_brief_2019}. In caso di denoising per analisi di immagini mediche questo presenta un grande problema in quando mantenere pi\`{u} dettagli possibili dell'immagine originale \`{e} di fondamentale importanza. \\
    I problemi principali nel denoising di immagini mediche sono:
    \begin{itemize}
      \item Le regioni piatte (zone aventi una variazione minima dei valori dei pixel) dell'immagine devono rimanere zone piatte.
      \item I contorni degli oggetti devono rimanere preservati.
      \item I dettagli di struttura dell'oggetto non devono essere persi.
      \item Il contrasto dell'immagine deve essere preservato.
      \item Non devono formarsi nuovo artefatti.
    \end{itemize}
    Generalmente ci sono due approcci per il denoising di immagini : spatial domain filtering e transform domain filtering \cite{jain_survey_2016}.

    \subsubsection{Filtri Spaziali}

    I filtri spaziali agiscono applicando un filtro direttamente all' immagine con rumore, e possono essere definiti in filtri lineari e non lineari.
    \subsubsection{Filtri Lineari}
      I filtri lineari come il filtro medio (Mean filter) o il filtro di Wiener tendono a sfocare i bordi dell' oggetto, distruggere linee e dettagli nell'immagine, e generalmente non performano bene nel caso di rumore dipendente dal segnale come il rumore poissoniano.
      L'idea del filtro medio \`{e} molto semplice, consiste nel sostituire ogni valore di ogni pixel con il valore medio dei pixel vicini, incluso se stesso.
      Il filto di Wiener invece richiede informazioni sullo spettro del rumore e dell'immagine originale.
    \subsubsection{Filtri Non Lineari}
      I filtri non lineari invece rimuovono il rumore senza cercare di identificarlo. Per cercare di risolvere i problemi dei filtri lineari una serie di filtri non lineari sono stati sviluppati: filtro mediano, filtro mediano pesato e filtro mediano rilassato.

    \subsubsection{Transform Domain Filtering}
    A differenza dei metodi spaziali, i metodi di trasformazione prima ottengono una trasformazione dell' immagine rumorosa e successivamente applicano la procedura di denoising sulla trasformazione.
    Si dividono in fitri Data adaptive e Non-Data adaptive.

  \subsection{Deep Learning}
    I metodi di \textbf{Machine Learning} si dividono in supervisionati, semi-supervisionati e non supervisionati. I metodi supervisionati utilizzano delle informazioni associate all' input (labels) per imparare dei parametri e trainare il modello di denoising. Per esempio dato il seguente modello \begin{equation*} y = x + \mu \end{equation*} dove x, y e $\mu$ rappresentano rispettivamente l' immagine originale, l' immagine rumorosa e un rumore additivo Gaussiano (AWGN) con deviazione standard $\sigma$. Il modello di denoising utilizza le coppie $ \{x_k, y_k\}^N_{k=1}$ per imparare i parametri della funzione $f$ che cerca di rimuovere il rumore, dove $x_k$ e $y_k$ sono la k-esima immagine originale e la k-esima immagine con rumore; N \'{e} il numero di immagini totali. Il processo pu\`{o} essere descritto come \begin{equation*} x_k = f(y_k, \theta, m)\end{equation*} dove $\theta$ sono i parametri e m la quantit\`{a} di rumore. \\
    I metodi non supervisionati utilizzano gli esempi di training per cercare patterns nel data al posto di fare label matching come nel caso supervisionato. \\Nel caso dei metodi semi-supervisionati invece si cerca di imparare una distribuzione del data in modo da poter assegnare labels ai dati che non ne hanno.\\
    Le \textbf{Reti Neurali} sono alla base dei metodi di machine learning, che a loro volta sono alla base dei metodi di deep learning. La maggior parte delle reti neurali sono composte da neuroni, input $X$, funzioni di attivazione $\phi$, pesi $W = [W^0, W^1,...,W^{n-1}]$ e bias $b = [b^0, b^1, b^n-1]$. A differenza dei modelli lineari come la regressione lineare e la regressione logistica, che possono modellizzare solo funzioni lineari senza comprendere l'interazioni tra due qualsiasi variabili di input, le reti neurali non applicano un modello lineare direttamente ad \textbf{x}. Viene utilizzata invece una trasformazione $\phi(\boldsymbol{x})$, dove $\phi$ \`{e} una trasformazione non lineare.

    \begin{equation}
        y = f(\boldsymbol{X}; \boldsymbol{b}, \boldsymbol{W}) = \phi(\boldsymbol{W}^T\boldsymbol{X} + \boldsymbol{b})
    \end{equation}

    Se la rete neurale \`{e} composta da pi\`{u} "livelli" di profondit\`{a}, dati da funzioni di attivazione e pesi diversi, la rete viene definita con il termine \textbf{multilayer perceptrons} (MLPs) oppure \textbf{Deep feedforward networks} o \textbf{feedforward neural networks}. \\
    L' obbiettivo delle reti feedforward \`{e} quello di approssimare una funzione $f^*$. Per esempio nel caso di un classificatore , $y = f^*(\textbf{x})$ mappa un input \textbf{x} ad una categoria $y$. Una rete feedforward definisce un mapping $\boldsymbol{y}=f(\boldsymbol{x} ; \boldsymbol{\theta})$ ed impara il valore dei parametri $\boldsymbol{\theta}$ che permettono a $f$ di meglio approssimare $f^*$. Queste reti sono chiamate \textbf{feedforward} perch\`{e} le informazioni fluiscono dall' input \textbf{x}, attraverso le funzioni intermedie che compongono $f$, per arrivare all' output \textbf{y}. Non ci sono connessioni \textbf{feedback} nelle quali l'output del modelo viene restituito al modello stesso.\\
    Le feedforward neural networks vengono chiamate \textbf{networks} perch\`{e} tipicamente sono rappresentate dalla composizione di funzioni diverse. Per esempio potremmo avere tre funzioni $f^{1}, f^{2}, f^{3}$ composte tra di loro per formare $f(\boldsymbol{x}) = f^{3}(f^{2}(f^{1}(\boldsymbol{x}))))$. In questo caso, $f^{1}$ \`{e} chiamato il primo layer, $f^{2}$ il secondo layer e cosi via. La lunghezza della catena definisce la \textbf{depth} del modello, da questa terminologia deriva il termine "deep learning". \\
    L'ultimo layer della rete neurale viene detto \textbf{output layer}. \\Durante il training della rete neurale , l' obbiettivo \`{e} quello di far assomigliare $f( \boldsymbol{x} )$ a $f^*(\boldsymbol{x})$.\\ Il data di training \`{e} composto da dei punti \textbf{x}, ognuno associato ad una label $\boldsymbol{y} \approx f^*(\boldsymbol{x})$. Il data di training specifica quale deve essere il comportamento dell' output layer per ogni punto \textbf{x}, cio\`{e} produrre valori vicini a \textbf{y}. L' algoritmo di training deve decidere come variare i parametri degli altri layer in modo tale da ottenere la migliore approssimazione di $f^*$, per fare questo viene utilizzata una \textbf{loss function} che descrive quanto il valore in output della rete su input $\boldsymbol{x}$ sia "distante" secondo una qualche metrica dalla label associata. \\Siccome l'output dei layer intermedi non mostrano l'output desiderato, questi layers vengono chiamati \textbf{hidden layers}.

    In fine questo tipo di reti vengono definite \textit{neurali} perch\`{e} sono ispirate alle neuroscienze. Ogni hidden layer della rete prende tipicamente in input un vettore di valori. La grandezza di questo vettore determina la \textbf{width} della rete. Ogni elemento di questo vettore pu\`{o} essere interpretato come un segnale per un neurone. Invece di pensare ad un hidden layer come una funzione che mappa un vettore in un altro, possiamo considerare ogni layer come composti da un insieme di \textbf{units} che operano in parallelo. Ogni unit assomiglia ad un neurone, nel senso che riceve degli input da molte altre unit e computa la propria funzione di attivazione. \\Nonostante questa intuizione, non bisogna pensare alle reti neurali come modellizzazioni del cervello, ma piuttosto come macchine che approssimano funzioni in modo tale da raggiungere una generalizzazione statistica del problema dato un insieme di esempi.

    Una rete neurale pu\`{o} essere espressa nel seguente modo :
    \begin{equation}
      f(X;W;b) = \phi^{n-1}(W^{n-1}\phi^{n-2}(W^{n-2}...\phi^0(W^0X + b^0)...b^{n-2}) + b^{n-1})
    \end{equation}

    \begin{figure}
      \begin{center}
        \includegraphics[scale=0.3]{mlp.png}
        \caption[esempio di Feedforward Neural Network]{Rete neurale a due layer}
        \label{fig:prima}
      \end{center}
    \end{figure}

    La rete neurale in figura \ref{fig:prima} completamente connessa presenta due layer : un hidden layer e un layer di output (Il layer di input solitamente non viene considerato come layer). I parametri $x_1, x_2, x_3$ e $o_1$ rappresentano l'input e l'output della rete. $ w_1, w_2, ..., w_{12}$ sono i pesi e $b_1, b_2, b_3, b_4$ \`{e} il bias. Per esempio, l'output del neurone $h_1$ si ottiene come segue :
    \begin{equation}
      f(z_{h1}) = f(w1x1 + w4x2 + w7x3 + b1)
    \end{equation}

    \begin{equation}
      o(h1) = f(z_{h1})
    \end{equation}

    Una volta calcolato l'output $o_1$ la rete usa un algoritmo di back propagation e una funzione di loss per imparare i parametri \cite{Goodfellow-et-al-2016}.

    Nell' ambito dell' elaborazioni delle immagini una tipologia di rete neurale molto utilizzata \`{e} la \textbf{Convolutional Neural Network} (CNN).\\
    Le Convolutional Network sono delle reti neurali specializzate per processare del data con una topologia a griglia. Un esempio sono le serie temporali, che possono essere rappresentate come una griglia 1D prendendo osservazioni ad intervalli regolari, e immagini, rappresentabili come una griglia 2D di pixel. Il nome "convolutional network" indica che la rete utilizza una particolare operazione matematica lineare denominata \textbf{convoluzione}. Utilizziamo un esempio per spiegare l'operazione di convoluzione : supponiamo di voler tracciare la posizione di un astronave con un sensore laser. Il sensore restituisce un singolo output $x(t)$, la posizione dell' astronave al tempo t. Sia $x$ che $t$ sono  valori reali.
    Supponiamo che il sensore restituisca output rumorosi. Per ottenere una stima meno rumorosa della posizione dell' astronave vogliamo utilizzare una media pesata tra le misurazioni dando pi\`{u} importanza alle misurazioni recenti. Possiamo utilizzare una funzione di pesatura $w(\alpha)$ dove $\alpha$ \`{e} il tempo della misurazione. Applicando questa media pesata ad ogni istante si ottiene una nuova funzione $s$ che indica una stima regolarizzata della posizione.
    \begin{equation}
      s(t)=\int x(a) w(t-a) d a
      \label{eq:1}
    \end{equation}
    Questa operazione viene detta \textbf{convoluzione}. L' operazione viene tipicamente denotata con un asterisco.
    \begin{equation*}
      s(t)=(x * w)(t)
    \end{equation*}
    Nel nostro esempio, $w$ deve essere una funzione di densit\`{a} valida, altrimenti l'output non sarebbe una media pesata. Ma questo non \`{e} necessario per altri esempi, in generale la convoluzione \`{e} devinita per ogni coppia di funzioni dove l'integrale \ref{eq:1} \`{e} definito; e l'operazione pu\`{o} essere usata per altri scopi oltre alla media pesata.
    Nella terminologia delle convoluzioni il primo termine, in questo caso la funzione $x$, prende il nome di \textbf{input}. Il secondo argomento viene detto \textbf{kernel}. L'output viene indicato con il termine \textbf{feature map}.
    Nelle applicazioni di machine learning l'input \`{e} solitamente discretizzato e rappresentato da un array multidimensionale, e il kernel \`{e} rappresentato da un array multidimensionale di parametri adattati dall' algoritmo di apprendimento. \\Nel caso di immagini vogliamo definire la convoluzione su pi\`{u} assi. Per esempio con un immagine due-dimensionale $I$ come input, vogliamo utilizzare un kernel due-dimensionale $K$ :
    \begin{equation*}
      S(i, j)=(I * K)(i, j)=\sum_{m} \sum_{n} I(m, n) K(i-m, j-n)
    \end{equation*}

    \begin{figure}
      \begin{center}
        \includegraphics[scale=0.3]{convolution.png}
        \caption[Rappresentazione dell' operazione di convoluzione]{Un esempio di convoluzione 2D}
        \label{fig:terza}
      \end{center}
    \end{figure}

    Le CNNs per come sono definite sono in grado di sfruttare le correlazioni spaziali dell' immagine \cite{Goodfellow-et-al-2016, tian_deep_2020, gondara_medical_2016}, preservando bordi e dettagli.\\
    Un avanzamento importante alle CNNs \`{e} stato dato dalla funzione di attivazione ReLU \cite{xu_empirical_2015, tian_deep_2020}, migliorando la velocit\`{a} della discesa stocastica del gradiente (SGD) \cite{Goodfellow-et-al-2016}, un metodo molto utilizzato per il training dei parametri del kernel. Sperimentalmente \`{e} stato osservato che se la rete \`{e} molto profonda, durante il training si possono presentare fenomini di annullameto o esplosione del gradiente; e se la rete \`{e} molto ampia, si pu\`{o} presentare il fenomeno dell' overfitting \cite{Goodfellow-et-al-2016}. Per risolvere questi problemi nel 2016 \`{e} stato proposto un particolare tipo di rete, ResNet \cite{he_deep_2015}.

    ResNet introduce il concetto di \textit{skip connection}: l'input di un layer \`{e} aggiunto all'output di un layer successivo. L' obbiettivo di una rete neurale \`{e} quello di modellizzare una funzione target $h(\textbf{x})$. Aggiungendo l' input \textbf{x} all' output della rete, allora la rete \`{e} costretta ad imparare una funzione $f(\textbf{x}) = h(\textbf{x}) - \textbf{x}$. Questa tecnica prende il nome di \textit{residual learning}.  Figura \ref{fig:seconda}.

    \begin{figure}
      \begin{center}
        \includegraphics[scale=0.3]{resnet.png}
        \caption[Residual Learning]{Un esempio di blocco residuo}
        \label{fig:seconda}
      \end{center}
    \end{figure}
    Quando si inizializza una rete neurale i suoi pesi sono vicini a zero e la rete restituisce in output valori vicini a zero. Aggiungendo una skip connection, la rete restituir\`{a} in output una copia del suo input; modellando inizialmente la funzione identit\`{a}. Se la funzione target \`{e} abbastanza vicina alla funzione di identit\`{a} (particolarmente vero per il problema del denoising), il residual learning velocizza l' apprendimento dei parametri in maniera considerevole.

\chapter{Denoising Residual Network}
  \section{Modellizzazione del Rumore}
    Lo scopo delle tecniche di denoising \`{e} quello di generare una immagine pulita X dato un input rumoroso Y, ottenuto secondo un modello di degradazione $Y = D(X)$.
    Per il rumore Gaussiano additivo (AWGN), il valore del pixel i-esimo  \`{e} :
    \begin{equation}
        y_{i}=D\left(x_{i}\right)=x_{i}+n_{i}
    \end{equation}
    Dove $n_{i} \sim \mathcal{N}\left(0, \sigma^{2}\right)$ \`{e} un rumore Gaussiano i.i.d con media zero e varianza $\sigma^{2}$.
    AWGN \`{e} usato per modellare rumore termico indipendente dal segnale elaborato e altri errori introdotti dall' elaborazione dell' immagine come descritto in precedenza.
    La degradazione dell'immagine dovuta al cosidetto rumore quantico viene invece modellata usando un rumore di Poisson dipendente dal segnale :

    \begin{equation}
      y_{i}=D\left(x_{i}\right)=p_{i}, \quad p_{i} \sim \mathcal{P}\left(x_{i}\right)
    \end{equation}

    dove $\mathcal{P}\left(x_{i}\right)$ \`{e} una variablie aleatoria di Poisson con media $x_i$. Siccome la distribuzione di Poisson tende alla distribuzion di Gauss per valori abbastanza grandi di $\lambda$ , $\mathcal{P}(\lambda) \approx \mathcal{N}(\lambda, \lambda)$ , il rumore generato in sistemi che catturano immagini \`{e} meglio modellato come un rumore di Poisson con AWGN, chiamato \textbf{Poisson-Gaussian} :

    \begin{equation}
      y_{i}=D\left(x_{i}\right)=\alpha p_{i}+n_{i}, \quad \alpha>0
    \end{equation}
    che \`{e} stato verificato da risultati sperimentali \cite{foi_practical_2008}.

  \section{DN-Resnet}
    DN-Resnet \cite{ren_dn-resnet_2018} consiste in una rete neurale composti da blocchi residui (ResBlocks), inseriti gradualmente nella rete durante il training. Questa strategia di training permette alla rete di convergere pi\`{u} velocemente. In aggiunta al convenzionale \textbf{errore quadratico medio} (MSE) si utilizza anche un funzione di loss \textbf{edge-aware} e una \textbf{perceptual loss} basata su Resnet-50 \cite{he_deep_2015}.\\
    Aggiungendo in cascata 5 Resblocks la rete raggiunge performance da stato dell' arte su tutti e tre i tipi di rumore, Gaussian, Poisson e Poisson-Gaussian. Rispetto ad altre reti neurali proposte per il problema del denoising, DN-Resnet ha un tempo di training molto minore e pu\`{o} essere eseguita in tempo reale.

    Dato un dataset di training $\left\{X_{i}, Y_{i}\right\}, i=1, \ldots, N$ con $N$ esempi, l'obbiettivo \`{e} quello di imparare un modello $S$ che predice immagini pulite $\hat{X}_{i}=S\left(Y_{i}\right)$ .\\
    L' elemento base di DN-Resnet \`{e} un ResBlock semplificato, come mostrato in figura \ref{fig:resblocks}(a). A differenza del ResBlock standard sono stati rimossi i layer di batch normalization \cite{ioffe_batch_2015} e il layer di ReLU dopo la somma residua, perch\`{e} rimuovere questi layer nelle reti residue basate su feature-map non peggiora le performance della rete \cite{lim_enhanced_2017}.

    \begin{figure}
      \begin{center}
        \includegraphics[scale=0.3]{resblocks.png}
        \caption [ResBlocks in DN-Resnet]{(a) Standard ResBlock, (b) ResBlock in DN-Resnet}
        \label{fig:resblocks}
      \end{center}
    \end{figure}

    DN-Resnet viene costruita concatenando i ResBlock in figura \ref{fig:resblocks}(b). Per velocizzare il training, viene utilizzato il metodo del \textbf{cascade training} \cite{ren_ct-srcnn_2017}, che separa il training in stage trainati uno alla volta.\\ Il training di DN-Resnet inizia come un modello di CNN a tre layer. Il primo layer consiste in $64$ $9\times9$ filtri. Il secondo layer consiste in $32$ $ 5\times5$. L'ultimo layer \`{e} composto da un layer $5 \times 5$. Tutte le convoluzioni hanno stride uno, e tutti i pesi sono inizializzati da una distribuzione Gaussiana con $\sigma = 0.001$. \\Dopo il training dei tre layer si procede con il cascade training come mostrato in figura \ref{fig:cascade}. Quando il training dello stage corrente \`{e} finito si passa allo stage successivo, rendendo pi\`{u} profonda la rete. In ogni stage viene aggiunto un ResBlock. Quindi la rete inizia con 3 layers, e si sviluppa in 5 layers, poi 7 layers, etc. \\Ogni layer convoluzionario nel ResBlock consiste in $32$ $3\times 3$ filtri, i nuovi layers vengono inseriti prima dell' ultimo layer $5 \times 5$. I pesi dei layers gia esistenti vengono ereditati dallo stage precedente, mentre i pesi del nuovo blocco vengono inizializzati randomicamente (Gaussian con $\sigma = 0.001$).
    Aggiungendo 5 ResBlock, la DN-Resnet risultante avr\`{a} $5 \times 2 + 3 = 13$ layers convoluzionari.

    \begin{figure}
      \begin{center}
        \includegraphics[scale=0.3]{cascadetraining.png}
        \caption [Cascade Training]{Cascade training di DN-Resnet. I cerchi denotano i layer convoluzionari standard, mentri i quadrati i ResBlock.}
        \label{fig:cascade}
      \end{center}
    \end{figure}

  \section{Funzione di loss Edge-aware}
  Molte reti di denoising puntano a minimizzare l' Errore Quadratico Medio (MSE) sul data di training.
  \begin{equation}
    \frac{1}{N} \sum_{i=1}^{N}\left\|X_{i}-\hat{X}_{i}\right\|^{2}
    \label{eq:mse}
  \end{equation}
   In questa rete viene utilizzata una funzione di loss dove ai pixel che rappresentano dei bordi dell' oggetto vengono assegnati pesi piu grandi rispetto agli altri pixel.

  \begin{equation}
    \operatorname{edge-loss}=w \times \frac{1}{N} \sum_{i=1}^{N}\left\|X_{i} M_{i}-\hat{X}_{i} M_{i}\right\|^{2}
    \label{eq:edge-aware}
  \end{equation}

  In Eq. \ref{eq:edge-aware}, \ref{eq:mse}, $X_i$ \`{e} l' i-esima immagine pulita, $\hat{X}_{i}$ \`{e} i-esima immagine a cui \`{e} stato applicato il denoising, $M$ \`{e} una edge map, $N$ \`{e} il numero di immagini e $w$ \`{e} una costante per controllare il trade-off tra i pixel negli edge e nel resto dell' immagine.

  Ci sono due vantaggi nell' applicare questa funzione di loss edge-aware. Il primo \`{e} che una delle sfide principali nel denoising consiste nella difficolta di riconoscere i bordi dell' oggetto, soprattuto in caso di rumore elevato, mentre aggiungere un vincolo nella funzione di loss risulta molto semplice. Il secondo \`{e} che dal punto di vista della qualit\`{a} dell' immagine, aumentare la precisione del denoising sui bordi dell' oggetto ne aumenta la definizione.

  M pu\`{o} essere costruito in due modi, tramite la magnitudine del gradiente ottenuto dai filtri di sobel o tramite una maschera binaria ottenuta impostando una soglia di valore del pixel da superare. I risultati migliori si ottengono tramite i \textbf{filtri di sobel}.\\
  L' operatore di sobel calcola un valore approssimato del valore in ogni punto del gradiente della funzione che rappresenta la luminosit\`{a} dell' immagine. L' operatore trova la direzione lungo il quale si ha il massimo incremento dal chiaro allo scuro, e la velocit\`{a} con cui avviene il cambiamento lungo questa direzione. Il risultato finale fornisce una misura di quanto bruscamente o gradualmente l' immagine cambia in quel punto, e quindi della probabilit\`{a} che quella parte di immagine rappresenti un contorno. In termini matematici, il gradiente di una funzione in due variabili \`{e} in ciascun punto dell' immagine un vettore bi-dimensionale le cui componenti sono le derivate del valore della luminosit\`{a} in direzione orizzontale e verticale. In ciascun punto dell' immagine questo vettore gradiente punta nella direzione di massimo aumento della luminosit\`{a}, e la lunghezza del vettore corrisponde alla rapidit\`{a} con cui la luminosit\`{a} cambia spostandosi in quella direzione. Nelle zone dell' immagine in cui la luminosit\`{a} \`{e} costante l' operatore di Sobel ha valore zero, mentre nei punti posti sui bordi \`{e} un vettore orientato attraveso il contorno, che punta nella direzione in cui si passa da valori di scuro a valori di chiaro.

  L' operatore applica una operazione di convoluzione utilizzando due kernel $3 \times 3$ all' immagine originale per calcolare i valori approssimati delle derivate lungo le due direzioni, orizzonatale e verticale. Chiamando $\mathbf{A}$ l' immagine sorgente, e $\mathbf{G}_{x}$, $\mathbf{G}_{y}$ la componente x ed y del gradiente, l' operazione \`{e} descritta da :
  \begin{equation}
    \mathbf{G}_{x}=\left[\begin{array}{lll}
    +1 & 0 & -1 \\
    +2 & 0 & -2 \\
    +1 & 0 & -1
    \end{array}\right] * \mathbf{A} \quad \text { e } \quad \mathbf{G}_{y}=\left[\begin{array}{ccc}
    +1 & +2 & +1 \\
    0 & 0 & 0 \\
    -1 & -2 & -1
    \end{array}\right] * \mathbf{A}
  \end{equation}
  dove $*$ indica l' operazione di convoluzione bi-dimensionale. In ogni punto dell' immagine, le approssimazioni del gradiente possono essere combinate per ottenere la magnitudine del gradiente :
  \begin{equation}
    \mathbf{G}=\sqrt{\mathbf{G}_{x}^{2}+\mathbf{G}_{y}{ }^{2}}
  \end{equation}

  \section{Perceptual Loss}
  L' errore quadratico medio \ref{eq:mse} calcola la distanza pixel per pixel del l'output del modello con l' immagine target. Questa differenza puntuale tende a lisciare i valori dei pixel e ad aumentare la sfocatura dell' immagine. Per ovviare a questi problemi viene introdotta una \textbf{multi scales perceptual loss} \cite{liang_edcnn_2020}, mostrata nella seguente formula :
  \begin{equation}
    L_{m u l t i-p}=\frac{1}{N S} \sum_{i=1}^{N} \sum_{s=1}^{S}\left\|\phi_{s}\left(F\left(x_{i}, \theta\right), \hat{\theta}\right)-\phi_{s}\left(y_{i}, \hat{\theta}\right)\right\|^{2}
  \end{equation}
  In questa formula, $x_i$ \`{e} l'input, $y_i$ \`{e} il target e $N$ \`{e} il numero di immagini. $F$ rappresenta la rete di denoising con parametri $\theta$. $\phi$ rappresenta un modello con dei pesi fissati pre-trainati $\hat{\theta}$, usato per calcolare la perceptual loss. S \`{e} il numero di stage usati nel modello pre-trainato.

  Per costruire la perceptual loss viene utilizzato Resnet-50 come estrattore delle feature map, in particolare sono stati rimossi i layer di pooling e i layer completamente connessi alla fine della rete, mantenendo solo i layer convoluzionari.\\ Inizialmente viene caricato il modello con i pesi trainati sul dataset ImageNet \cite{deng_imagenet_2009}, i pesi vengono poi "freezati" e resi non trainabili. Durante il calcolo del valore della perceptual loss, sia l'output denoised che l' immagine target vengono passati all' estrattore per fare forward propagation. Vengono scelte le feature map dei quattro stage di ResNet, il quale ognuno dimezza lo spazio dell' immagine, rappresentando caratteristiche spaziali in forme diverse. A questo punto viene utilizzato MSE per misurare la similitudine tra queste feature map. La multi-scale perceptual loss \`{e} ottenuta facendo la media tra queste similitudini.


  \begin{figure}
    \includegraphics[scale = 0.3]{multiscale.png}
    \caption[Multi-scale perceptual loss]{multi-scale perceptual loss basata su Resnet-50, composto da 4 stage principali \cite{he_deep_2015}}
    \label{fig:multiscale}
  \end{figure}

  \section{Compound Loss}
  Combinando le funzioni di loss descritte in precedenza otteniamo la funzione \ref{eq:compound loss}, che ha l'obbiettivo di ottenere una similitudine tra i valori dei pixel, mantenendo i dettagli strutturali dell' oggetto e aumentandone la definizione dei contorni.

  \begin{equation}
    L_{mse}= \frac{1}{N} \sum_{i=1}^{N}\left\|X_{i}-\hat{X}_{i}\right\|^{2}
  \end{equation}

  \begin{equation}
    L_{edge} = \frac{1}{N} \sum_{i=1}^{N}\left\|X_{i} M_{i}-\hat{X}_{i} M_{i}\right\|^{2}
  \end{equation}

  \begin{equation}
    L_{m u l t i-p}=\frac{1}{N S} \sum_{i=1}^{N} \sum_{s=1}^{S}\left\|\phi_{s}\left(F\left(x_{i}, \theta\right), \hat{\theta}\right)-\phi_{s}\left(y_{i},     \hat{\theta}\right)\right\|^{2}
  \end{equation}

  \begin{equation}
    L_{\text {compound }}=L_{m s e}+w_{p} \cdot L_{\text {multi- } p }+ w_{e} \cdot L_{edge}
    \label{eq:compound loss}
\end{equation}

\chapter{Risultati}
  \section{Datasets}
    Sono stati usati due dataset per valutare il modello, mini-MIAS contenente immagini di mammografie (MMM)\cite{suckling_mammographic_1994} e un dataset di panoramiche dentali (DX) \cite{abdi_panoramic_2017} . MMM \`{e} composto di 322 immagini di risoluzione $1024 \times 1024$, mentre da DX sono state usate XX immagini di risoluzione varia. Entrambi i dataset sono stati scalati ad una risoluzione $512 \times 512$.\\
    Per ridurre la dimensione della rete da ogni immagine sono state estratte delle patch $64 \times 64$. Il denoising avviene quindi sulle singole patch e successivamente viene ricostrutia l' immagine originale. Questo metodo genera una discontinuit\`{a} tra i valori dei pixel ai bordi delle patch, per ovviare a questo problema le patch vengono estratte dalle immagini usanto 8 pixel di overlap tra una patch e l' altra. Nella ricostruzione dell' immagine intera, dati gli 8 pixel sovrapposti, vengono presi 4 pixel da una patch e 4 pixel dall' altra per ogni coppia di patch con pixel sovrapposti.

    Il rumore di Poisson \`{e} un tipo di rumore dipendente dal segnale sottostante, e non pu\`{o} essere semplicemente sommato al segnale originale come nel caso di AWGN.\\
    Per generare rumore di Poisson \`{e} stata usata la seguente tecnica sviluppata da Knuth \cite[pp.~137-138]{knuth97}:
    \begin{lstlisting}
       L = $e^{-\lambda}$, k = 0, p = 1
      do:
        k = k + 1
        Genera un numero randomico uniforme u in [0, 1]
        p = p $\times$ u
      while:
        p > L
      return k - 1
    \end{lstlisting}
    L' idea dell' algoritmo \`{e} la seguente : Contare il numero di occorrenze di un evento che puo accadere in ogni istante, dato un intervallo di tempo finito, dove la media del numero di occorrenze dell'evento \`{e} $\lambda$. Nel nostro caso $\lambda$ \`{e} uguale al valore dell' i-esimo pixel.
    TODO inserisci immagini poisson
  \section{Valutazione del denoising}
    ssim e psnr
    tabella gaussian, poisson, gaussian+poisson
    Per valutare le performance di denoising sono state utilizzate due metriche standard, SSIM e PSNR.

    SSIM tra due immagini $X$ e $R$ \`{e} definito come segue:
    \begin{equation}
      \operatorname{SSIM}(X, R)=\frac{\left(2 \mu_{X} \mu_{R}+C_{1}\right)\left(2 \sigma_{X R}+C_{2}\right)}{\left(\mu_{X}^{2}+\mu_{R}^{2}+C_{1}\right)\left(\sigma_{X}^{2}+\sigma_{R}^{2}+C_{2}\right)}
    \end{equation}
    dove $\mu_{X}, \mu_{R}, \sigma_{X}^{2}, \sigma_{R}^{2}$ sono rispettivamente le medie e le varianze di $X$ e $R$, $\sigma_{X R}$ \`{e} la covarianza tra $X$ e $R$, e $C1$ e $C2$ sono costanti predefinite \cite{wang_image_2004}.\\
    SSIM serve a misurare le differenze tra due immagini in termini di luminosit\`{a}, contrasto e struttura. L' output di SSIM \`{e} un valore tra -1 e 1, dove valori vicino a uno indicano risultati migliori.

    Peak Signal-to-noise Ratio (PSNR) \`{e} un importante fattore per valutare il denoising. Rappresenta il rapporto tra la massima potenza di un segnale e la potenza del rumore che ne degrada la rappresentazione. Data un immagine originale $X$ e la stessa immagine sottoposta a denoising $R$, PSNR \`{e} definito cosi :
    \begin{equation}
      P S N R=10 \times \log _{10}\left(\frac{255 \times 255}{M S E}\right)
    \end{equation}
    considerando 255 come il massimo valore nell' immagine (8 bit per pixel). Valori pi\`{u} alti di PSNR rappresentano una similitudine maggiore tra l' immagine originale e quella pulita dal processo di denoising, rispetto a valori pi\`{u} bassi.

      \begin{center}
        \begin{tabular}{|c|c|c|c|}
          \hline
          DN-Resnet & sigma & edge & edge+perceptual\\
          \hline
          Parameters & - & 149,344 & 149,344\\
          \hline
          Gaussian & \begin{tabular}{@{}c@{}}0.05\\0.1\end{tabular}& \begin{tabular}{@{}c@{}} \color{blue} $0.9575 \pm 0.008/41.60 \pm 1.434$ \\ $0.9280 \pm 0.008/39.06 \pm 1.339$ \end{tabular} & \begin{tabular}{@{}c@{}} $0.9566 \pm 0.0085/41.34 \pm 1.465$\\ \color{red}$0.9319 \pm 0.0089/39.15 \pm 1.344$ \\ \end{tabular}\\
          \hline
          Poisson & - & $0.9725 \pm 0.009/40.92 \pm 1.51$ & \color{red}$0.9730 \pm 0.0088/40.87 \pm 1.492$\\
          \hline
          Poisson - Gaussian & \begin{tabular}{@{}c@{}}0.01\\0.02\\0.05\\0.1\end{tabular} & \begin{tabular}{@{}c@{}} $0.9682 \pm 0.0089/40.33 \pm 1.523$\\ \color{blue}$0.9668 \pm 0.0091/40.26 \pm 1.4923$ \\ \color{blue}$0.9491 \pm 0.0103/39.15 \pm 1.4511$ \\ $0.9130 \pm 0.010/36.97 \pm 1.349$ \end{tabular} & \begin{tabular}{@{}c@{}}\color{red}$0.9691 \pm 0.0089/40.37 \pm 1.1499$ \\ $0.9575 \pm 0.0077/39.92 \pm 1.1508$ \\ $0.9489 \pm 0.0096/38.86 \pm 1.4464$ \\ \color{red} $0.9254 \pm 0.0124/37.48 \pm 1.3428$ \end{tabular}\\
          \hline
        \end{tabular}
      \end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%non numera l'ultima pagina sinistra
\clearpage{\pagestyle{empty}\cleardoublepage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%per fare le conclusioni
\chapter*{Conclusioni}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%imposta l'intestazione di pagina
\rhead[\fancyplain{}{\bfseries
CONCLUSIONI}]{\fancyplain{}{\bfseries\thepage}}
\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries
CONCLUSIONI}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%aggiunge la voce Conclusioni
                                        %   nell'indice
\addcontentsline{toc}{chapter}{Conclusioni} Queste sono le
conclusioni.ssssssss

\printbibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%non numera l'ultima pagina sinistra
\clearpage{\pagestyle{empty}\cleardoublepage}
\chapter*{Ringraziamenti}
\thispagestyle{empty}
Qui possiamo ringraziare il mondo intero!!!!!!!!!!\\
Ovviamente solo se uno vuole, non \`e obbligatorio.
\end{document}
