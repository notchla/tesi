@article{ren_ct-srcnn_2017,
	title = {{CT}-{SRCNN}: {Cascade} {Trained} and {Trimmed} {Deep} {Convolutional} {Neural} {Networks} for {Image} {Super} {Resolution}},
	shorttitle = {{CT}-{SRCNN}},
	url = {http://arxiv.org/abs/1711.04048},
	abstract = {We propose methodologies to train highly accurate and efficient deep convolutional neural networks (CNNs) for image super resolution (SR). A cascade training approach to deep learning is proposed to improve the accuracy of the neural networks while gradually increasing the number of network layers. Next, we explore how to improve the SR efficiency by making the network slimmer. Two methodologies, the one-shot trimming and the cascade trimming, are proposed. With the cascade trimming, the network's size is gradually reduced layer by layer, without significant loss on its discriminative ability. Experiments on benchmark image datasets show that our proposed SR network achieves the state-of-the-art super resolution accuracy, while being more than 4 times faster compared to existing deep super resolution networks.},
	urldate = {2021-06-23},
	journal = {arXiv:1711.04048 [cs]},
	author = {Ren, Haoyu and El-Khamy, Mostafa and Lee, Jungwon},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.04048},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/notchla/Zotero/storage/NFVBPWN6/Ren et al. - 2017 - CT-SRCNN Cascade Trained and Trimmed Deep Convolu.pdf:application/pdf;arXiv.org Snapshot:/home/notchla/Zotero/storage/4UICNLY7/1711.html:text/html},
}

@article{lim_enhanced_2017,
	title = {Enhanced {Deep} {Residual} {Networks} for {Single} {Image} {Super}-{Resolution}},
	url = {http://arxiv.org/abs/1707.02921},
	abstract = {Recent research on super-resolution has progressed with the development of deep convolutional neural networks (DCNN). In particular, residual learning techniques exhibit improved performance. In this paper, we develop an enhanced deep super-resolution network (EDSR) with performance exceeding those of current state-of-the-art SR methods. The significant performance improvement of our model is due to optimization by removing unnecessary modules in conventional residual networks. The performance is further improved by expanding the model size while we stabilize the training procedure. We also propose a new multi-scale deep super-resolution system (MDSR) and training method, which can reconstruct high-resolution images of different upscaling factors in a single model. The proposed methods show superior performance over the state-of-the-art methods on benchmark datasets and prove its excellence by winning the NTIRE2017 Super-Resolution Challenge.},
	urldate = {2021-06-23},
	journal = {arXiv:1707.02921 [cs]},
	author = {Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Lee, Kyoung Mu},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.02921},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/notchla/Zotero/storage/XNW993Z4/Lim et al. - 2017 - Enhanced Deep Residual Networks for Single Image S.pdf:application/pdf;arXiv.org Snapshot:/home/notchla/Zotero/storage/YCZ4UVT3/1707.html:text/html},
}

@article{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2021-06-23},
	journal = {arXiv:1502.03167 [cs]},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv: 1502.03167},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/notchla/Zotero/storage/6QHP292F/Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf;arXiv.org Snapshot:/home/notchla/Zotero/storage/H3U8B5RW/1502.html:text/html},
}

@article{foi_practical_2008,
	title = {Practical {Poissonian}-{Gaussian} {Noise} {Modeling} and {Fitting} for {Single}-{Image} {Raw}-{Data}},
	volume = {17},
	issn = {1941-0042},
	doi = {10.1109/TIP.2008.2001399},
	abstract = {We present a simple and usable noise model for the raw-data of digital imaging sensors. This signal-dependent noise model, which gives the pointwise standard-deviation of the noise as a function of the expectation of the pixel raw-data output, is composed of a Poissonian part, modeling the photon sensing, and Gaussian part, for the remaining stationary disturbances in the output data. We further explicitly take into account the clipping of the data (over- and under-exposure), faithfully reproducing the nonlinear response of the sensor. We propose an algorithm for the fully automatic estimation of the model parameters given a single noisy image. Experiments with synthetic images and with real raw-data from various sensors prove the practical applicability of the method and the accuracy of the proposed model.},
	number = {10},
	journal = {IEEE Transactions on Image Processing},
	author = {Foi, Alessandro and Trimeche, Mejdi and Katkovnik, Vladimir and Egiazarian, Karen},
	month = oct,
	year = {2008},
	note = {Conference Name: IEEE Transactions on Image Processing},
	keywords = {Additive white noise, Clipping, Digital images, digital imaging sensors, Fitting, Gaussian noise, Hardware, Image sensors, noise estimation, noise modeling, Optoelectronic and photonic sensors, overexposure, Poisson noise, raw-data, Sensor phenomena and characterization, Signal processing, Thermal sensors},
	pages = {1737--1754},
	file = {IEEE Xplore Full Text PDF:/home/notchla/Zotero/storage/6LHPK3UG/Foi et al. - 2008 - Practical Poissonian-Gaussian Noise Modeling and F.pdf:application/pdf;IEEE Xplore Abstract Record:/home/notchla/Zotero/storage/AMFI7WVU/4623175.html:text/html},
}

@article{ren_dn-resnet_2018,
	title = {{DN}-{ResNet}: {Efficient} {Deep} {Residual} {Network} for {Image} {Denoising}},
	shorttitle = {{DN}-{ResNet}},
	url = {http://arxiv.org/abs/1810.06766},
	abstract = {A deep learning approach to blind denoising of images without complete knowledge of the noise statistics is considered. We propose DN-ResNet, which is a deep convolutional neural network (CNN) consisting of several residual blocks (ResBlocks). With cascade training, DN-ResNet is more accurate and more computationally eﬃcient than the state of art denoising networks. An edge-aware loss function is further utilized in training DN-ResNet, so that the denoising results have better perceptive quality compared to conventional loss function. Next, we introduce the depthwise separable DN-ResNet (DS-DN-ResNet) utilizing the proposed Depthwise Seperable ResBlock (DS-ResBlock) instead of standard ResBlock, which has much less computational cost. DS-DN-ResNet is incrementally evolved by replacing the ResBlocks in DN-ResNet by DS-ResBlocks stage by stage. As a result, high accuracy and good computational eﬃciency are achieved concurrently. Whereas previous state of art deep learning methods focused on denoising either Gaussian or Poisson corrupted images, we consider denoising images having the more practical Poisson with additive Gaussian noise as well. The results show that DN-ResNets are more eﬃcient, robust, and perform better denoising than current state of art deep learning methods, as well as the popular variants of the BM3D algorithm, in cases of blind and non-blind denoising of images corrupted with Poisson, Gaussian or Poisson-Gaussian noise. Our network also works well for other image enhancement task such as compressed image restoration.},
	language = {en},
	urldate = {2021-06-13},
	journal = {arXiv:1810.06766 [cs, eess]},
	author = {Ren, Haoyu and El-Khamy, Mostafa and Lee, Jungwon},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.06766},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Ren et al. - 2018 - DN-ResNet Efficient Deep Residual Network for Ima.pdf:/home/notchla/Zotero/storage/PR7WHXHF/Ren et al. - 2018 - DN-ResNet Efficient Deep Residual Network for Ima.pdf:application/pdf},
}

@article{liang_edcnn_2020,
	title = {{EDCNN}: {Edge} enhancement-based {Densely} {Connected} {Network} with {Compound} {Loss} for {Low}-{Dose} {CT} {Denoising}},
	shorttitle = {{EDCNN}},
	url = {http://arxiv.org/abs/2011.00139},
	doi = {10.1109/ICSP48669.2020.9320928},
	abstract = {In the past few decades, to reduce the risk of X-ray in computed tomography (CT), low-dose CT image denoising has attracted extensive attention from researchers, which has become an important research issue in the ﬁeld of medical images. In recent years, with the rapid development of deep learning technology, many algorithms have emerged to apply convolutional neural networks to this task, achieving promising results. However, there are still some problems such as low denoising efﬁciency, over-smoothed result, etc. In this paper, we propose the Edge enhancement based Densely connected Convolutional Neural Network (EDCNN). In our network, we design an edge enhancement module using the proposed novel trainable Sobel convolution. Based on this module, we construct a model with dense connections to fuse the extracted edge information and realize end-to-end image denoising. Besides, when training the model, we introduce a compound loss that combines MSE loss and multi-scales perceptual loss to solve the over-smoothed problem and attain a marked improvement in image quality after denoising. Compared with the existing lowdose CT image denoising algorithms, our proposed model has a better performance in preserving details and suppressing noise.},
	language = {en},
	urldate = {2021-06-13},
	journal = {2020 15th IEEE International Conference on Signal Processing (ICSP)},
	author = {Liang, Tengfei and Jin, Yi and Li, Yidong and Wang, Tao and Feng, Songhe and Lang, Congyan},
	month = dec,
	year = {2020},
	note = {arXiv: 2011.00139},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	pages = {193--198},
	file = {Liang et al. - 2020 - EDCNN Edge enhancement-based Densely Connected Ne.pdf:/home/notchla/Zotero/storage/LL3LLQXC/Liang et al. - 2020 - EDCNN Edge enhancement-based Densely Connected Ne.pdf:application/pdf},
}

@article{diwakar_review_2018,
	title = {A review on {CT} image noise and its denoising},
	volume = {42},
	issn = {17468094},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1746809418300107},
	doi = {10.1016/j.bspc.2018.01.010},
	language = {en},
	urldate = {2021-06-14},
	journal = {Biomedical Signal Processing and Control},
	author = {Diwakar, Manoj and Kumar, Manoj},
	month = apr,
	year = {2018},
	pages = {73--88},
	file = {Diwakar and Kumar - 2018 - A review on CT image noise and its denoising.pdf:/home/notchla/Zotero/storage/75ZIR5G9/Diwakar and Kumar - 2018 - A review on CT image noise and its denoising.pdf:application/pdf},
}

@article{manson_image_nodate,
	title = {Image {Noise} in {Radiography} and {Tomography}: {Causes}, {Effects} and {Reduction} {Techniques}},
	abstract = {The presence of noise in images produced by medical imaging equipment is common and unavoidable. Image noise can obscure and stimulate pathology, even sometimes to the extent of making them diagnostically unusable. To minimize noise in medical images, it is essential to comprehend the sources of noise and how they occur. In this paper, we have reviewed different sources of noise that are present in images produced in radiography and tomography imaging techniques, the causes, effects and the various ways that are employed in their reduction. In order to completely eliminate noise in radiological imaging systems, we recommend that detectors that are free from noise should be designed and incorporated into future imaging systems.},
	language = {en},
	journal = {Medical Imaging},
	author = {Manson, EN and Ampoh, V Atuwo and Fiagbedzi, E and Amuasi, J H and Flether, J J and Schandorf, C},
	pages = {6},
	file = {Manson et al. - Image Noise in Radiography and Tomography Causes,.pdf:/home/notchla/Zotero/storage/PYE8ICAU/Manson et al. - Image Noise in Radiography and Tomography Causes,.pdf:application/pdf},
}

@article{boyat_review_2015,
	title = {A {Review} {Paper} : {Noise} {Models} in {Digital} {Image} {Processing}},
	volume = {6},
	issn = {22293922, 0976710X},
	shorttitle = {A {Review} {Paper}},
	url = {http://www.aircconline.com/sipij/V6N2/6215sipij06.pdf},
	doi = {10.5121/sipij.2015.6206},
	abstract = {Noise is always presents in digital images during image acquisition, coding, transmission, and processing steps. Noise is very difficult to remove it from the digital images without the prior knowledge of noise model. That is why, review of noise models are essential in the study of image denoising techniques. In this paper, we express a brief overview of various noise models. These noise models can be selected by analysis of their origin. In this way, we present a complete and quantitative analysis of noise models available in digital images.},
	language = {en},
	number = {2},
	urldate = {2021-06-16},
	journal = {Signal \& Image Processing : An International Journal},
	author = {Boyat, Ajay Kumar and Joshi, Brijendra Kumar},
	month = apr,
	year = {2015},
	pages = {63--75},
	file = {Boyat and Joshi - 2015 - A Review Paper  Noise Models in Digital Image Pro.pdf:/home/notchla/Zotero/storage/T4LGB8A9/Boyat and Joshi - 2015 - A Review Paper  Noise Models in Digital Image Pro.pdf:application/pdf},
}

@article{tian_deep_2020,
	title = {Deep {Learning} on {Image} {Denoising}: {An} overview},
	shorttitle = {Deep {Learning} on {Image} {Denoising}},
	url = {http://arxiv.org/abs/1912.13171},
	abstract = {Deep learning techniques have received much attention in the area of image denoising. However, there are substantial differences in the various types of deep learning methods dealing with image denoising. Speciﬁcally, discriminative learning based on deep learning can ably address the issue of Gaussian noise. Optimization models based on deep learning are effective in estimating the real noise. However, there has thus far been little related research to summarize the different deep learning techniques for image denoising. In this paper, we offer a comparative study of deep techniques in image denoising. We ﬁrst classify the deep convolutional neural networks (CNNs) for additive white noisy images; the deep CNNs for real noisy images; the deep CNNs for blind denoising and the deep CNNs for hybrid noisy images, which represents the combination of noisy, blurred and low-resolution images. Then, we analyze the motivations and principles of the different types of deep learning methods. Next, we compare the state-of-the-art methods on public denoising datasets in terms of quantitative and qualitative analysis. Finally, we point out some potential challenges and directions of future research.},
	language = {en},
	urldate = {2021-06-17},
	journal = {arXiv:1912.13171 [cs, eess]},
	author = {Tian, Chunwei and Fei, Lunke and Zheng, Wenxian and Xu, Yong and Zuo, Wangmeng and Lin, Chia-Wen},
	month = aug,
	year = {2020},
	note = {arXiv: 1912.13171},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Tian et al. - 2020 - Deep Learning on Image Denoising An overview.pdf:/home/notchla/Zotero/storage/CZGX59IB/Tian et al. - 2020 - Deep Learning on Image Denoising An overview.pdf:application/pdf},
}

@article{fan_brief_2019,
	title = {Brief review of image denoising techniques},
	volume = {2},
	issn = {2524-4442},
	url = {https://vciba.springeropen.com/articles/10.1186/s42492-019-0016-7},
	doi = {10.1186/s42492-019-0016-7},
	abstract = {With the explosion in the number of digital images taken every day, the demand for more accurate and visually pleasing images is increasing. However, the images captured by modern cameras are inevitably degraded by noise, which leads to deteriorated visual image quality. Therefore, work is required to reduce noise without losing image features (edges, corners, and other sharp structures). So far, researchers have already proposed various methods for decreasing noise. Each method has its own advantages and disadvantages. In this paper, we summarize some important research in the field of image denoising. First, we give the formulation of the image denoising problem, and then we present several image denoising techniques. In addition, we discuss the characteristics of these techniques. Finally, we provide several promising directions for future research.},
	language = {en},
	number = {1},
	urldate = {2021-06-17},
	journal = {Visual Computing for Industry, Biomedicine, and Art},
	author = {Fan, Linwei and Zhang, Fan and Fan, Hui and Zhang, Caiming},
	month = dec,
	year = {2019},
	pages = {7},
	file = {Fan et al. - 2019 - Brief review of image denoising techniques.pdf:/home/notchla/Zotero/storage/V6W28IBZ/Fan et al. - 2019 - Brief review of image denoising techniques.pdf:application/pdf},
}

@article{jain_survey_2016,
	title = {A survey of edge-preserving image denoising methods},
	volume = {18},
	issn = {1572-9419},
	url = {https://doi.org/10.1007/s10796-014-9527-0},
	doi = {10.1007/s10796-014-9527-0},
	abstract = {Reducing noise has always been one of the standard problems of the image analysis and processing community. Often though, at the same time as reducing the noise in a signal, it is important to preserve the edges. Edges are of critical importance to the visual appearance of images. So, it is desirable to preserve important features, such as edges, corners and other sharp structures, during the denoising process. This paper presents a review of some significant work in the area of image denoising. It provides a brief general classification of image denoising methods. The main aim of this survey is to provide evolution of research in the direction of edge-preserving image denoising. It characterizes some of the well known edge-preserving denoising methods, elaborating each of them, and discusses the advantages and drawbacks of each. Basic ideas and improvement of the denoising methods are also comprehensively summarized and analyzed in depth. Often, researchers face difficulty in selecting an appropriate denoising method that is specific to their purpose. We have classified and systemized these denoising methods. The key goal of this paper is to provide researchers with background on a progress of denoising methods so as to make it easier for researchers to choose the method best suited to their aims.},
	language = {en},
	number = {1},
	urldate = {2021-06-17},
	journal = {Information Systems Frontiers},
	author = {Jain, Paras and Tyagi, Vipin},
	month = feb,
	year = {2016},
	pages = {159--170},
	file = {Springer Full Text PDF:/home/notchla/Zotero/storage/LDEEMCG7/Jain and Tyagi - 2016 - A survey of edge-preserving image denoising method.pdf:application/pdf},
}

@article{gondara_medical_2016,
	title = {Medical image denoising using convolutional denoising autoencoders},
	url = {http://arxiv.org/abs/1608.04667},
	doi = {10.1109/ICDMW.2016.0041},
	abstract = {Image denoising is an important pre-processing step in medical image analysis. Different algorithms have been proposed in past three decades with varying denoising performances. More recently, having outperformed all conventional methods, deep learning based models have shown a great promise. These methods are however limited for requirement of large training sample size and high computational costs. In this paper we show that using small sample size, denoising autoencoders constructed using convolutional layers can be used for efﬁcient denoising of medical images. Heterogeneous images can be combined to boost sample size for increased denoising performance. Simplest of networks can reconstruct images with corruption levels so high that noise and signal are not differentiable to human eye.},
	language = {en},
	urldate = {2021-06-17},
	journal = {2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW)},
	author = {Gondara, Lovedeep},
	month = dec,
	year = {2016},
	note = {arXiv: 1608.04667},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	pages = {241--246},
	file = {Gondara - 2016 - Medical image denoising using convolutional denois.pdf:/home/notchla/Zotero/storage/PSZ6KC9E/Gondara - 2016 - Medical image denoising using convolutional denois.pdf:application/pdf},
}

@article{nair_rectified_nodate,
	title = {Rectified {Linear} {Units} {Improve} {Restricted} {Boltzmann} {Machines}},
	abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an inﬁnite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these “Stepped Sigmoid Units” are unchanged. They can be approximated eﬃciently by noisy, rectiﬁed linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face veriﬁcation on the Labeled Faces in the Wild dataset. Unlike binary units, rectiﬁed linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
	language = {en},
	author = {Nair, Vinod and Hinton, Geoffrey E},
	pages = {8},
	file = {Nair and Hinton - Rectified Linear Units Improve Restricted Boltzman.pdf:/home/notchla/Zotero/storage/6RAMNAPX/Nair and Hinton - Rectified Linear Units Improve Restricted Boltzman.pdf:application/pdf},
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2021-06-18},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/notchla/Zotero/storage/ZJ2WF9R8/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf;arXiv.org Snapshot:/home/notchla/Zotero/storage/ZKUSYPG6/1512.html:text/html},
}

@article{geron_hands-machine_nodate,
	title = {Hands-{On} {Machine} {Learning} with {Scikit}-{Learn}, {Keras}, and {TensorFlow}},
	language = {en},
	author = {Géron, Aurélien},
	pages = {851},
	file = {Géron - Hands-On Machine Learning with Scikit-Learn, Keras.pdf:/home/notchla/Zotero/storage/297P33NP/Géron - Hands-On Machine Learning with Scikit-Learn, Keras.pdf:application/pdf},
}

@article{xu_empirical_2015,
	title = {Empirical {Evaluation} of {Rectified} {Activations} in {Convolutional} {Network}},
	url = {http://arxiv.org/abs/1505.00853},
	abstract = {In this paper we investigate the performance of diﬀerent types of rectiﬁed activation functions in convolutional neural network: standard rectiﬁed linear unit (ReLU), leaky rectiﬁed linear unit (Leaky ReLU), parametric rectiﬁed linear unit (PReLU) and a new randomized leaky rectiﬁed linear units (RReLU). We evaluate these activation function on standard image classiﬁcation task. Our experiments suggest that incorporating a nonzero slope for negative part in rectiﬁed activation units could consistently improve the results. Thus our ﬁndings are negative on the common belief that sparsity is the key of good performance in ReLU. Moreover, on small scale dataset, using deterministic negative slope or learning it are both prone to overﬁtting. They are not as eﬀective as using their randomized counterpart. By using RReLU, we achieved 75.68\% accuracy on CIFAR-100 test set without multiple test or ensemble.},
	language = {en},
	urldate = {2021-06-19},
	journal = {arXiv:1505.00853 [cs, stat]},
	author = {Xu, Bing and Wang, Naiyan and Chen, Tianqi and Li, Mu},
	month = nov,
	year = {2015},
	note = {arXiv: 1505.00853},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Xu et al. - 2015 - Empirical Evaluation of Rectified Activations in C.pdf:/home/notchla/Zotero/storage/FS6AJX33/Xu et al. - 2015 - Empirical Evaluation of Rectified Activations in C.pdf:application/pdf},
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
